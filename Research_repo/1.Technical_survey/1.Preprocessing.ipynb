{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2e73123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def preprocess(df, num_cols, bin_cols, multi_cols, verbose=True):\n",
    "    \"\"\"\n",
    "    Preprocess the DF for ML\n",
    "    Args:\n",
    "        df(pd.DataFrame): dataset you are working on\n",
    "        num_cols(list): list of all numerical features\n",
    "        bin_cols(list): list of all binary features\n",
    "        multi_cols(list): list of all multicategorical features\n",
    "        verbose(string): if you want to print a head on the final DF\n",
    "    Returns:\n",
    "        None\n",
    "    Example:\n",
    "    telcom = preprocess(telcom.copy(), num_cols, bin_cols, verbose=True)    \n",
    "    \"\"\"    \n",
    "    #Label encoding Binary columns, which means if two values M, F -> 0, 1\n",
    "    # here is to convert object type to int\n",
    "    le = LabelEncoder()\n",
    "    for i in bin_cols :\n",
    "        df[i] = le.fit_transform(df[i])\n",
    "    \n",
    "    #Duplicating columns for multi value columns\n",
    "    df = pd.get_dummies(data = df,columns = multi_cols )\n",
    "\n",
    "    # Scaling Numerical columns\n",
    "    std = StandardScaler()\n",
    "    scaled = std.fit_transform(df[num_cols])\n",
    "    scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "    # dropping original values merging scaled values for numerical columns\n",
    "    df = df.drop(columns = num_cols,axis = 1)\n",
    "    df = df.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "    \n",
    "    df.columns = map(str.lower, df.columns)\n",
    "\n",
    "    if verbose == True:\n",
    "        print(df.head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def data_preprocessing(dataset):\n",
    "    \"\"\"\n",
    "    Bank\n",
    "    \"\"\"\n",
    "    if dataset==\"Bank\":\n",
    "        target_col = [\"Exited\"]\n",
    "\n",
    "        df = pd.read_csv('/home/ec2-user/SageMaker/data/churn_package/datasets/Bank-data/Churn_Modelling.csv', sep=\",\")\n",
    "\n",
    "        cat_cols   = df.nunique()[df.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(df.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in df.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = df.nunique()[df.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "\n",
    "        del df[\"CustomerId\"]\n",
    "        del df[\"Surname\"]\n",
    "\n",
    "        multi_cols = ['NumOfProducts', 'Geography']\n",
    "        num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "        # --------- general preprocessing --------- #\n",
    "\n",
    "        df = preprocess(df, num_cols, bin_cols, multi_cols, verbose=False)\n",
    "\n",
    "        # rename the target variable to Churn\n",
    "        df.rename(columns={\"exited\":\"churn\"}, inplace=True)\n",
    "\n",
    "        target_col = [\"churn\"]\n",
    "\n",
    "        del df[\"rownumber\"]\n",
    "        return df\n",
    "\n",
    "        \n",
    "    elif dataset==\"UCI\":\n",
    "        \"\"\"\n",
    "        UCI\n",
    "        \"\"\"\n",
    "        target_col = [\"churn\"]\n",
    "        df = pd.read_csv('/home/ec2-user/SageMaker/data/churn_package/datasets/UCI/UCI.csv', sep=\",\")\n",
    "\n",
    "        cat_cols   = df.nunique()[df.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(df.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in df.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = df.nunique()[df.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "\n",
    "        del df[\"state\"]\n",
    "\n",
    "        del df[\"phone number\"]\n",
    "        multi_cols = ['area code']\n",
    "\n",
    "\n",
    "        df = preprocess(df, num_cols, bin_cols, multi_cols, verbose=False)\n",
    "        return df\n",
    "    \n",
    "    elif dataset == 'Mobile':        \n",
    "        df = pd.read_csv('/home/ec2-user/SageMaker/data/churn_package/datasets/mobile-churn/mobile-churn-data.csv', sep=\",\")\n",
    "\n",
    "        target_col = [\"churn\"]\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = df.nunique()[df.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(df.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in df.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = df.nunique()[df.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "\n",
    "        del df[\"year\"]\n",
    "        del df[\"month\"]\n",
    "        del df[\"user_account_id\"]\n",
    "\n",
    "        cat_cols   = df.nunique()[df.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(df.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in df.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = df.nunique()[df.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        df[multi_cols] = df[multi_cols].apply(lambda x: x.str.replace(',','.'))\n",
    "        df[multi_cols] = df[multi_cols].apply(pd.to_numeric)\n",
    "\n",
    "        num_cols = num_cols + multi_cols\n",
    "\n",
    "        multi_cols = []\n",
    "        df = preprocess(df.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "        # une fois que j'ai changer la virgule en point, j'ai eu masse NaN bizarre\n",
    "        df = df.fillna(df.mean())\n",
    "        return df\n",
    "    \n",
    "    elif dataset == 'KKBox':\n",
    "        \n",
    "        # ------ input ------ #        \n",
    "        dataset_name_train = '/home/ec2-user/SageMaker/data/churn_package/datasets/KKBox/train_v2.csv'\n",
    "        dataset_name_transaction = '/home/ec2-user/SageMaker/data/churn_package/datasets/KKBox/transactions_v2.csv'\n",
    "        dataset_name_log = '/home/ec2-user/SageMaker/data/churn_package/datasets/KKBox/user_logs_v2.csv'\n",
    "        dataset_name_mem = '/home/ec2-user/SageMaker/data/churn_package/datasets/KKBox/members_v3.csv'\n",
    "\n",
    "        sep = \",\"\n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"Churn\"]\n",
    "\n",
    "        # data for writing file\n",
    "        dataset = \"KKBox\"\n",
    "\n",
    "        train = pd.read_csv(dataset_name_train)\n",
    "        transa = pd.read_csv(dataset_name_transaction)\n",
    "        log = pd.read_csv(dataset_name_log)\n",
    "        member = pd.read_csv(dataset_name_mem)\n",
    "\n",
    "        train = pd.merge(train, member, on=\"msno\", how=\"left\")\n",
    "        del member\n",
    "\n",
    "        train = pd.merge(train,transa,how='left',on='msno',left_index=True, right_index=True)\n",
    "        del transa\n",
    "\n",
    "        train = pd.merge(train,log,how='left',on='msno',left_index=True, right_index=True)\n",
    "        del log\n",
    "\n",
    "        train['registration_init_time'] = train['registration_init_time'].fillna(value='20151009')\n",
    "        train[\"transaction_date\"] = pd.to_datetime(train[\"transaction_date\"])\n",
    "        train[\"date\"] = pd.to_datetime(train[\"date\"])\n",
    "        train[\"membership_expire_date\"] = pd.to_datetime(train[\"membership_expire_date\"])\n",
    "        train[\"registration_init_time\"] = pd.to_datetime(train[\"registration_init_time\"])\n",
    "\n",
    "        def date_feature(df):\n",
    "\n",
    "            col = ['registration_init_time' ,'transaction_date','membership_expire_date','date']\n",
    "            var = ['reg','trans','mem_exp','user_']\n",
    "            #df['duration'] = (df[col[1]] - df[col[0]]).dt.days \n",
    "\n",
    "            for i ,j in zip(col,var):\n",
    "                df[j+'_day'] = df[i].dt.day.astype('uint8')\n",
    "                df[j+'_weekday'] = df[i].dt.weekday.astype('uint8')        \n",
    "                df[j+'_month'] = df[i].dt.month.astype('uint8') \n",
    "                df[j+'_year'] =df[i].dt.year.astype('uint16') \n",
    "\n",
    "        date_feature(train)\n",
    "\n",
    "        col = [ 'city', 'bd', 'gender', 'registered_via']\n",
    "        def missing(df,columns):\n",
    "            col = columns\n",
    "            for i in col:\n",
    "                df[i].fillna(df[i].mode()[0],inplace=True)\n",
    "\n",
    "        missing(train,col)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        train['gender'] = le.fit_transform(train['gender'])\n",
    "\n",
    "        def OHE(df):\n",
    "            #col = df.select_dtypes(include=['category']).columns\n",
    "            col = ['city','gender','registered_via']\n",
    "            print('Categorical columns in dataset',col)\n",
    "\n",
    "            c2,c3 = [],{}\n",
    "            for c in col:\n",
    "                if df[c].nunique()>2 :\n",
    "                    c2.append(c)\n",
    "                    c3[c] = 'ohe_'+c\n",
    "\n",
    "            df = pd.get_dummies(df,columns=c2,drop_first=True,prefix=c3)\n",
    "            \n",
    "            return df\n",
    "        train1 = OHE(train)\n",
    "\n",
    "        unwanted = ['msno','registration_init_time','transaction_date','membership_expire_date','date']\n",
    "\n",
    "        train1.drop(unwanted,axis=1, inplace=True)\n",
    "        # rename the target variable to Churn\n",
    "        train1.rename(columns={\"is_churn\":\"churn\"}, inplace=True)\n",
    "        return train1\n",
    "    \n",
    "    elif dataset == \"K2009\":\n",
    "        \n",
    "        # ------ input ------ #\n",
    "        # Data file opening\n",
    "        dataset_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/Kdd2009-small/orange_small_train.data'\n",
    "        target_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/Kdd2009-small/orange_small_train_churn.labels'\n",
    "        sep = \"\\t\"\n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"churn\"]\n",
    "\n",
    "        # data for writing file\n",
    "        dataset = \"KDD-cup-2009-small\"\n",
    "\n",
    "        telcom = pd.read_csv(dataset_name, sep=\"\\t\")\n",
    "        target = pd.read_csv(target_name, sep=\"\\t\")\n",
    "\n",
    "        target.columns = [\"churn\"]\n",
    "\n",
    "        # merge training set with its target\n",
    "        telcom = telcom.join(target)\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(telcom.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "\n",
    "        # list of columns\n",
    "        old_col_telcom = telcom.columns\n",
    "\n",
    "\n",
    "        # ----------- Preprocessing ----------- #\n",
    "\n",
    "        # last observation is -0.788 for the churn so we remove it\n",
    "        telcom = telcom[:-1]\n",
    "\n",
    "        del telcom[\"churn\"]\n",
    "\n",
    "        # data cleaning: drop the columns with std close to zero\n",
    "        # delete columns with at least 20% missing values\n",
    "        threshold = 0.2\n",
    "        telcom = telcom.drop(telcom.std()[telcom.std() < threshold].index.values, axis=1)\n",
    "        telcom = telcom.loc[:, pd.notnull(telcom).sum() > len(telcom)*.8]\n",
    "\n",
    "        DataVars = telcom.columns\n",
    "        data_types = {Var: telcom[Var].dtype for Var in DataVars}\n",
    "\n",
    "        for Var in DataVars:\n",
    "            if data_types[Var] == int:\n",
    "                x = telcom[Var].astype(float)\n",
    "                telcom.loc[:, Var] = x\n",
    "                data_types[Var] = x.dtype\n",
    "            elif data_types[Var] != float:\n",
    "                x = telcom[Var].astype('category')\n",
    "                telcom.loc[:, Var] = x\n",
    "                data_types[Var] = x.dtype\n",
    "\n",
    "        # numerical data\n",
    "        float_DataVars = [Var for Var in DataVars\n",
    "                             if data_types[Var] == float]\n",
    "\n",
    "        float_x_means = telcom.mean()\n",
    "\n",
    "        for Var in float_DataVars:\n",
    "            x = telcom[Var]\n",
    "            isThereMissing = x.isnull()\n",
    "            if isThereMissing.sum() > 0:\n",
    "                telcom.loc[isThereMissing.tolist(), Var] = float_x_means[Var]     \n",
    "\n",
    "        DataVars = telcom.columns\n",
    "\n",
    "        categorical_DataVars = [Var for Var in DataVars\n",
    "                                   if data_types[Var] != float]\n",
    "\n",
    "        categorical_levels = telcom[categorical_DataVars].apply(lambda col: len(col.cat.categories))\n",
    "\n",
    "        categorical_DataVars = categorical_levels[categorical_levels <= 500].index\n",
    "\n",
    "        col_to_keep = float_DataVars + list(categorical_DataVars)\n",
    "\n",
    "        telcom = telcom[col_to_keep]\n",
    "\n",
    "        collapsed_categories = {}\n",
    "\n",
    "        removed_categorical_DataVars = set()\n",
    "\n",
    "        for Vars in categorical_DataVars:\n",
    "\n",
    "            isTheremissing_value = telcom[Vars].isnull()\n",
    "            if isTheremissing_value.sum() > 0:\n",
    "                telcom[Vars].cat.add_categories('unknown', inplace=True)\n",
    "                telcom.loc[isTheremissing_value.tolist(), Vars] = 'unknown'\n",
    "\n",
    "        cat_cols = telcom.select_dtypes(\"category\").columns\n",
    "        num_cols = telcom.select_dtypes(\"float\").columns\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        # merge training set with its target\n",
    "        telcom = telcom.join(target)\n",
    "\n",
    "        # changing labels to 0 or 1\n",
    "        telcom[\"churn\"] = (telcom[\"churn\"] +1)/2\n",
    "\n",
    "        # convert to int the target variable othw it is 1.0 and 0.0\n",
    "        telcom.churn = pd.to_numeric(telcom.churn, downcast='integer')\n",
    "\n",
    "        telcom = preprocess(telcom.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "        return telcom\n",
    "\n",
    "    elif dataset == \"Member\":\n",
    "        \n",
    "        # ------ input ------ #\n",
    "        # Data file opening\n",
    "        dataset_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/membershipWoes/Assignment- Membership woes.csv'\n",
    "        sep = \",\"\n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"Churn\"]\n",
    "\n",
    "        # data for writing file\n",
    "        dataset = \"membership-woes\"\n",
    "\n",
    "        telcom = pd.read_csv(dataset_name, sep)\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "        telcom.rename(columns = {'MEMBERSHIP_STATUS': \"Churn\"}, inplace=True)\n",
    "        telcom[\"Churn\"].map({'INFORCE': 0, 'CANCELLED': 1})\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(telcom.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "        # preprocessing\n",
    "        del telcom['START_DATE (YYYYMMDD)']\n",
    "        del telcom['MEMBERSHIP_NUMBER']\n",
    "        del telcom[\"AGENT_CODE\"]\n",
    "        del telcom['END_DATE  (YYYYMMDD)']\n",
    "\n",
    "        num_cols = ['MEMBERSHIP_TERM_YEARS',\n",
    "         'ANNUAL_FEES',\n",
    "         'MEMBER_ANNUAL_INCOME',\n",
    "         'MEMBER_AGE_AT_ISSUE']\n",
    "\n",
    "        multi_cols =  ['ADDITIONAL_MEMBERS',\n",
    "         'MEMBER_OCCUPATION_CD',\n",
    "         'PAYMENT_MODE',\n",
    "         'MEMBER_MARITAL_STATUS']\n",
    "\n",
    "        # replace nan by most frequent value\n",
    "        telcom[\"MEMBER_OCCUPATION_CD\"].fillna(telcom[\"MEMBER_OCCUPATION_CD\"].mode().iloc[0], inplace=True)\n",
    "        telcom[\"MEMBER_GENDER\"].fillna(telcom[\"MEMBER_GENDER\"].mode().iloc[0], inplace=True)\n",
    "        telcom[\"MEMBER_MARITAL_STATUS\"].fillna(telcom[\"MEMBER_MARITAL_STATUS\"].mode().iloc[0], inplace=True)\n",
    "\n",
    "        # for numerical values replace nan by mean\n",
    "\n",
    "        telcom.fillna(telcom.mean(), inplace=True)\n",
    "\n",
    "        telcom = preprocess(telcom.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "        return telcom\n",
    "    \n",
    "    \n",
    "    elif dataset == \"TelE\":\n",
    "\n",
    "        # ------ input ------ #\n",
    "        # Data file opening\n",
    "        path = \"/Churn/datasets\"\n",
    "        dataset_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/churn-telco-europa/train_churn_kg.csv'\n",
    "\n",
    "        sep = \",\"\n",
    "        \n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"CHURN\"]\n",
    "\n",
    "        # data for writing file\n",
    "        dataset = \"telco-europa\"\n",
    "\n",
    "        telcom = pd.read_csv(dataset_name, sep)\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "        # None\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(telcom.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "        # write report\n",
    "\n",
    "        # --------- general preprocessing --------- #\n",
    "\n",
    "        del telcom[\"CETEL_NUMBER\"]\n",
    "        del telcom[\"CNI_CUSTOMER\"]\n",
    "\n",
    "\n",
    "        num_cols = ['DAYS_LIFE',\n",
    "         'DEVICE_TECNOLOGY',\n",
    "         'MIN_PLAN',\n",
    "         'PRICE_PLAN',\n",
    "         'TOT_MIN_CALL_OUT',\n",
    "         'AVG_MIN_CALL_OUT_3',\n",
    "         'TOT_MIN_IN_ULT_MES',\n",
    "         'AVG_MIN_IN_3',\n",
    "         'ROA_LASTMONTH',\n",
    "         'ROACETEL_LAST_MONTH',\n",
    "         'DEVICE',\n",
    "         'STATE_DATA',\n",
    "         'CITY_DATA',\n",
    "         'STATE_VOICE',\n",
    "         'CITY_VOICE']\n",
    "\n",
    "        multi_cols = ['TEC_ANT_DATA', 'TEC_ANT_VOICE']\n",
    "\n",
    "        telcom = preprocess(telcom.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "\n",
    "        target_col = [\"churn\"]\n",
    "\n",
    "        # ----- post preprocessing ----- #\n",
    "        telcom.fillna(telcom.mean(), inplace=True)\n",
    "        return telcom\n",
    "    \n",
    "    \n",
    "    elif dataset == \"TelC\":\n",
    "    \n",
    "        # ------ input ------ #\n",
    "        # Data file opening\n",
    "        sep = \",\"\n",
    "        dataset_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/TelcoCustChurn/Telco_Customer_Churn.csv'\n",
    "       \n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"Churn\"]\n",
    "\n",
    "        # data for writing file\n",
    "        dataset = \"TelcoCustChurn\"\n",
    "\n",
    "        telcom = pd.read_csv(dataset_name, sep)\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "        #Replacing blank spaces with null values in total charges column\n",
    "        telcom['TotalCharges'] = telcom[\"TotalCharges\"].replace(\" \",np.nan)\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(telcom.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "        # write report\n",
    "\n",
    "\n",
    "        #Dropping null values from total charges column which contain .15% missing data \n",
    "        #telcom = telcom[telcom[\"TotalCharges\"].notnull()]\n",
    "        #telcom = telcom.reset_index()[telcom.columns]\n",
    "\n",
    "        # replace missing values by mean there are only 11 missing values\n",
    "        telcom[\"TotalCharges\"] = pd.to_numeric(telcom[\"TotalCharges\"])\n",
    "        telcom[\"TotalCharges\"] = telcom[\"TotalCharges\"].fillna(telcom[\"TotalCharges\"].mean())\n",
    "        \n",
    "        total_charges = telcom[\"TotalCharges\"]\n",
    "\n",
    "        #replace 'No internet service' to No for the following columns\n",
    "        replace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                        'TechSupport','StreamingTV', 'StreamingMovies']\n",
    "        for i in replace_cols : \n",
    "            telcom[i]  = telcom[i].replace({'No internet service' : 'No'})\n",
    "\n",
    "        #replace values\n",
    "        telcom[\"SeniorCitizen\"] = telcom[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n",
    "\n",
    "        #Tenure to categorical column\n",
    "        def tenure_lab(telcom) :\n",
    "\n",
    "            if telcom[\"tenure\"] <= 12 :\n",
    "                return \"Tenure_0-12\"\n",
    "            elif (telcom[\"tenure\"] > 12) & (telcom[\"tenure\"] <= 24 ):\n",
    "                return \"Tenure_12-24\"\n",
    "            elif (telcom[\"tenure\"] > 24) & (telcom[\"tenure\"] <= 48) :\n",
    "                return \"Tenure_24-48\"\n",
    "            elif (telcom[\"tenure\"] > 48) & (telcom[\"tenure\"] <= 60) :\n",
    "                return \"Tenure_48-60\"\n",
    "            elif telcom[\"tenure\"] > 60 :\n",
    "                return \"Tenure_gt_60\"\n",
    "        telcom[\"tenure_group\"] = telcom.apply(lambda telcom:tenure_lab(telcom),\n",
    "                                              axis = 1)\n",
    "\n",
    "        #Drop tenure column\n",
    "        #telcom = telcom.drop(columns = \"tenure_group\",axis = 1)\n",
    "\n",
    "        Id_col     = ['customerID']\n",
    "        target_col = [\"Churn\"]\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 6].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col + Id_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        # --------- general preprocessing --------- #\n",
    "        del telcom[\"customerID\"]\n",
    "        telcom = preprocess(telcom.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "\n",
    "        return telcom\n",
    "    \n",
    "    elif dataset == \"C2C\":\n",
    "\n",
    "        # ------ input ------ #\n",
    "        # Data file opening\n",
    "        path = \"/Churn/datasets\"\n",
    "        dataset_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/Cell2Cell/cell2celltrain.csv'\n",
    "\n",
    "        sep = \",\"\n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"churn\"]\n",
    "\n",
    "        # data for writing file\n",
    "        dataset = \"Cell2Cell\"\n",
    "\n",
    "        # training dataset\n",
    "        telcom = pd.read_csv(dataset_name, sep)\n",
    "\n",
    "        # Unknown in the dataset is a NaN\n",
    "        telcom.replace('Unknown', np.nan, inplace=True)\n",
    "        # replace NaN by mean\n",
    "        telcom.fillna(telcom.mean(), inplace=True)\n",
    "        # Delete\n",
    "        del telcom[\"CustomerID\"]\n",
    "\n",
    "        telcom.fillna(telcom.mean(), inplace=True)\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(telcom.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        telcom = preprocess(telcom.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "        \n",
    "        return telcom\n",
    "    \n",
    "    elif dataset == \"SATO\":\n",
    "        \n",
    "        # ------ input ------ #\n",
    "        # Data file opening\n",
    "        path = \"/Churn/datasets\"\n",
    "        #dataset_name = \"south-asian/South Asian Wireless Telecom Operator (SATO 2015).csv\"\n",
    "        dataset_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/south-asian/South Asian Wireless Telecom Operator (SATO 2015).csv'\n",
    "\n",
    "        sep = \",\"\n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"churn\"]\n",
    "\n",
    "        # data for writing file\n",
    "        dataset = \"south-asian\"\n",
    "\n",
    "        # ------ writing scoring report ------ #\n",
    "        path_out = f\"Churn/reporting/dashboard-scoring/{dataset}.csv\"\n",
    "\n",
    "        telcom = pd.read_csv(dataset_name, sep)\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "        # rename the target variable to Churn\n",
    "        telcom.rename(columns={\"Class\":\"churn\"}, inplace=True)\n",
    "\n",
    "        # change the \"Churned\" to 1\n",
    "        telcom[target_col[0]].replace(\"Churned\", \"1\", inplace=True)\n",
    "\n",
    "        # change the active to 0\n",
    "        telcom[target_col[0]].replace(\"Active\", \"0\", inplace=True)\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(telcom.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        # --------- general preprocessing --------- #\n",
    "\n",
    "        telcom = preprocess(telcom.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "        \n",
    "        return telcom\n",
    "    \n",
    "\n",
    "    elif dataset == \"HR\":\n",
    "        # ------ input ------ #\n",
    "        # Data file opening\n",
    "        path = \"/Churn/datasets\"\n",
    "        dataset_name = \"IBM-HR/WA_Fn-UseC_-HR-Employee-Attrition.csv\"\n",
    "        dataset_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/IBM-HR/WA_Fn-UseC_-HR-Employee-Attrition.csv'\n",
    "\n",
    "        sep = \",\"\n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"Attrition\"]\n",
    "\n",
    "        # data for writing file\n",
    "        dataset = \"IBM-HR\"\n",
    "\n",
    "        telcom = pd.read_csv(dataset_name, sep)\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(telcom.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "        telcom = preprocess(telcom.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "        telcom = telcom.rename(columns={'attrition': 'churn'})    \n",
    "        \n",
    "        return telcom\n",
    "    \n",
    "    elif dataset == \"DSN\":\n",
    "        # ------ input ------ #\n",
    "        # Data file opening\n",
    "        dataset_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/DSN-telecom-churn/TRAIN.csv'\n",
    "\n",
    "        sep = \",\"\n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"Churn Status\"]\n",
    "\n",
    "        telcom = pd.read_csv(dataset_name, sep)\n",
    "\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(telcom.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        telcom = telcom[:-1] \n",
    "\n",
    "        del telcom['Customer ID']\n",
    "\n",
    "        # works only on numerical data\n",
    "        telcom.fillna(telcom.mean(), inplace=True)\n",
    "\n",
    "        telcom['Network type subscription in Month 1'].fillna(telcom['Most Loved Competitor network in in Month 1'].mode().iloc[0], inplace=True)\n",
    "        telcom['Network type subscription in Month 2'].fillna(telcom['Most Loved Competitor network in in Month 1'].mode().iloc[0], inplace=True)\n",
    "\n",
    "\n",
    "        telcom['Most Loved Competitor network in in Month 1'].fillna(telcom['Most Loved Competitor network in in Month 1'].mode().iloc[0], inplace=True)\n",
    "        telcom['Most Loved Competitor network in in Month 2'].fillna(telcom['Most Loved Competitor network in in Month 1'].mode().iloc[0], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "        # remove the last obs. of the dataset, the churn value is \"0.5\" and it is the only one\n",
    "        telcom[\"Churn Status\"] = telcom.drop(telcom.index[-1])[\"Churn Status\"]\n",
    "        #telcom = telcom[:-1]\n",
    "\n",
    "        multi_cols = ['Most Loved Competitor network in in Month 2',\n",
    "         'Network type subscription in Month 1',\n",
    "         'Network type subscription in Month 2',\n",
    "         'Most Loved Competitor network in in Month 1']\n",
    "\n",
    "        telcom = preprocess(telcom.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "        telcom = telcom.rename(columns={'churn status': 'churn'})   \n",
    "        \n",
    "        return telcom\n",
    "    \n",
    "    elif dataset == \"news\":\n",
    "\n",
    "        # ------ input ------ #\n",
    "        # Data file opening\n",
    "        path = \"/Churn/datasets\"\n",
    "        dataset_name = '/home/ec2-user/SageMaker/data/churn_package/datasets/newspaper/NewspaperChurn.csv'\n",
    "        sep = \",\"\n",
    "\n",
    "        # data preprocessing\n",
    "        target_col = [\"Churn\"]\n",
    "\n",
    "        # data for writing file\n",
    "        dataset = \"newspaper\"\n",
    "\n",
    "        # ------ writing scoring report ------ #\n",
    "\n",
    "\n",
    "        # training dataset\n",
    "        telcom = pd.read_csv(dataset_name, sep)\n",
    "\n",
    "        # set everything to lower except column\n",
    "        telcom = telcom.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "        # --------- Unique preprocessing for this data set --------- #\n",
    "\n",
    "        # rename the target variable to Churn\n",
    "        telcom.rename(columns={\"Subscriber\":\"Churn\"}, inplace=True)\n",
    "\n",
    "        # change the \"Churned\" to 1\n",
    "        telcom.Churn.replace(\"no\", \"0\", inplace=True)\n",
    "\n",
    "        # change the active to 0\n",
    "        telcom.Churn.replace(\"yes\", \"1\", inplace=True)\n",
    "\n",
    "        # ----------- Categorization ----------- #\n",
    "\n",
    "        cat_cols   = telcom.nunique()[telcom.nunique() < 10].keys().tolist()\n",
    "        cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "\n",
    "        cat_cols = list(set(cat_cols + list(telcom.select_dtypes(include=[\"object\"]).columns)))\n",
    "\n",
    "        num_cols   = [x for x in telcom.columns if x not in cat_cols + target_col]\n",
    "\n",
    "        #Binary columns with 2 values\n",
    "        bin_cols   = telcom.nunique()[telcom.nunique() == 2].keys().tolist()\n",
    "        #Columns more than 2 values\n",
    "        multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "        del telcom['Address']\n",
    "        del telcom[\"SubscriptionID\"]\n",
    "        del telcom['Zip Code']\n",
    "\n",
    "        # useless all the obs. came from CA state\n",
    "        del telcom['State']\n",
    "\n",
    "        num_cols = ['Year Of Residence', 'reward program']\n",
    "\n",
    "        multi_cols = ['weekly fee',\n",
    "         'Age range',\n",
    "         'City',\n",
    "         'Source Channel',\n",
    "         'County',\n",
    "         'Ethnicity',\n",
    "         'Deliveryperiod',\n",
    "         'Nielsen Prizm',\n",
    "         'HH Income',\n",
    "         'Language']\n",
    "\n",
    "        telcom = preprocess(telcom.copy(), num_cols, bin_cols, multi_cols, verbose=False)\n",
    "        return telcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe559ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>churn</th>\n",
       "      <th>area code_408</th>\n",
       "      <th>area code_415</th>\n",
       "      <th>area code_510</th>\n",
       "      <th>account length</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676489</td>\n",
       "      <td>1.234883</td>\n",
       "      <td>1.566767</td>\n",
       "      <td>0.476643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070610</td>\n",
       "      <td>-0.055940</td>\n",
       "      <td>-0.070427</td>\n",
       "      <td>0.866743</td>\n",
       "      <td>-0.465494</td>\n",
       "      <td>0.866029</td>\n",
       "      <td>-0.085008</td>\n",
       "      <td>-0.601195</td>\n",
       "      <td>-0.085690</td>\n",
       "      <td>-0.427932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149065</td>\n",
       "      <td>1.307948</td>\n",
       "      <td>-0.333738</td>\n",
       "      <td>1.124503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108080</td>\n",
       "      <td>0.144867</td>\n",
       "      <td>-0.107549</td>\n",
       "      <td>1.058571</td>\n",
       "      <td>0.147825</td>\n",
       "      <td>1.059390</td>\n",
       "      <td>1.240482</td>\n",
       "      <td>-0.601195</td>\n",
       "      <td>1.241169</td>\n",
       "      <td>-0.427932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902529</td>\n",
       "      <td>-0.591760</td>\n",
       "      <td>1.168304</td>\n",
       "      <td>0.675985</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.573383</td>\n",
       "      <td>0.496279</td>\n",
       "      <td>-1.573900</td>\n",
       "      <td>-0.756869</td>\n",
       "      <td>0.198935</td>\n",
       "      <td>-0.755571</td>\n",
       "      <td>0.703121</td>\n",
       "      <td>0.211534</td>\n",
       "      <td>0.697156</td>\n",
       "      <td>-1.188218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.428590</td>\n",
       "      <td>-0.591760</td>\n",
       "      <td>2.196596</td>\n",
       "      <td>-1.466936</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.742865</td>\n",
       "      <td>-0.608159</td>\n",
       "      <td>-2.743268</td>\n",
       "      <td>-0.078551</td>\n",
       "      <td>-0.567714</td>\n",
       "      <td>-0.078806</td>\n",
       "      <td>-1.303026</td>\n",
       "      <td>1.024263</td>\n",
       "      <td>-1.306401</td>\n",
       "      <td>0.332354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.654629</td>\n",
       "      <td>-0.591760</td>\n",
       "      <td>-0.240090</td>\n",
       "      <td>0.626149</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.038932</td>\n",
       "      <td>1.098699</td>\n",
       "      <td>-1.037939</td>\n",
       "      <td>-0.276311</td>\n",
       "      <td>1.067803</td>\n",
       "      <td>-0.276562</td>\n",
       "      <td>-0.049184</td>\n",
       "      <td>-0.601195</td>\n",
       "      <td>-0.045885</td>\n",
       "      <td>1.092641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   international plan  voice mail plan  churn  area code_408  area code_415  \\\n",
       "0                   0                1      0              0              1   \n",
       "1                   0                1      0              0              1   \n",
       "2                   0                0      0              0              1   \n",
       "3                   1                0      0              1              0   \n",
       "4                   1                0      0              0              1   \n",
       "\n",
       "   area code_510  account length  number vmail messages  total day minutes  \\\n",
       "0              0        0.676489               1.234883           1.566767   \n",
       "1              0        0.149065               1.307948          -0.333738   \n",
       "2              0        0.902529              -0.591760           1.168304   \n",
       "3              0       -0.428590              -0.591760           2.196596   \n",
       "4              0       -0.654629              -0.591760          -0.240090   \n",
       "\n",
       "   total day calls  ...  total eve minutes  total eve calls  total eve charge  \\\n",
       "0         0.476643  ...          -0.070610        -0.055940         -0.070427   \n",
       "1         1.124503  ...          -0.108080         0.144867         -0.107549   \n",
       "2         0.675985  ...          -1.573383         0.496279         -1.573900   \n",
       "3        -1.466936  ...          -2.742865        -0.608159         -2.743268   \n",
       "4         0.626149  ...          -1.038932         1.098699         -1.037939   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0             0.866743          -0.465494            0.866029   \n",
       "1             1.058571           0.147825            1.059390   \n",
       "2            -0.756869           0.198935           -0.755571   \n",
       "3            -0.078551          -0.567714           -0.078806   \n",
       "4            -0.276311           1.067803           -0.276562   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0           -0.085008         -0.601195          -0.085690   \n",
       "1            1.240482         -0.601195           1.241169   \n",
       "2            0.703121          0.211534           0.697156   \n",
       "3           -1.303026          1.024263          -1.306401   \n",
       "4           -0.049184         -0.601195          -0.045885   \n",
       "\n",
       "   customer service calls  \n",
       "0               -0.427932  \n",
       "1               -0.427932  \n",
       "2               -1.188218  \n",
       "3                0.332354  \n",
       "4                1.092641  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the dataset\n",
    "dataset = \"UCI\"\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = data_preprocessing(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c6008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76ddf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02cb550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (louis_default)",
   "language": "python",
   "name": "louis_default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
