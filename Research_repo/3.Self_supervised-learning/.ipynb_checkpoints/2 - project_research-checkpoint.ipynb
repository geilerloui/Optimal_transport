{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40309098",
   "metadata": {},
   "source": [
    "## Docs\n",
    "\n",
    "* https://forums.fast.ai/t/porto-seguro-winning-solution-representation-learning/8499 winning solution porto seguro\n",
    "* https://github.com/BenjiKCF/Tabular-data-Winning-Solution tabular solution to porto seguro\n",
    "* To do list\n",
    "    * To compare other variations of embeddings like using the class information for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec1df76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.146049</td>\n",
       "      <td>0.125349</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.119765</td>\n",
       "      <td>0.117086</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.115079</td>\n",
       "      <td>0.115402</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113351</td>\n",
       "      <td>0.113851</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110698</td>\n",
       "      <td>0.112079</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.108393</td>\n",
       "      <td>0.111241</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.106517</td>\n",
       "      <td>0.110763</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.106376</td>\n",
       "      <td>0.110466</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cat0_0</th>\n",
       "      <th>cat0_1</th>\n",
       "      <th>cat0_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277491</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292775</td>\n",
       "      <td>0.210421</td>\n",
       "      <td>0.335680</td>\n",
       "      <td>0.508110</td>\n",
       "      <td>0.375804</td>\n",
       "      <td>0.485737</td>\n",
       "      <td>0.388535</td>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>0.048048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59826</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717059</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.253756</td>\n",
       "      <td>0.810781</td>\n",
       "      <td>0.558822</td>\n",
       "      <td>0.821682</td>\n",
       "      <td>0.950494</td>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>0.048048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100532</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300573</td>\n",
       "      <td>0.807069</td>\n",
       "      <td>0.559432</td>\n",
       "      <td>0.310892</td>\n",
       "      <td>0.414348</td>\n",
       "      <td>0.328559</td>\n",
       "      <td>0.198210</td>\n",
       "      <td>-0.057172</td>\n",
       "      <td>-0.075411</td>\n",
       "      <td>-0.046009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127444</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260020</td>\n",
       "      <td>0.762579</td>\n",
       "      <td>0.929469</td>\n",
       "      <td>0.368868</td>\n",
       "      <td>0.400274</td>\n",
       "      <td>0.582639</td>\n",
       "      <td>0.436348</td>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>0.048048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268466</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292645</td>\n",
       "      <td>0.487171</td>\n",
       "      <td>0.581556</td>\n",
       "      <td>0.332349</td>\n",
       "      <td>0.366024</td>\n",
       "      <td>0.374952</td>\n",
       "      <td>0.382322</td>\n",
       "      <td>-0.057172</td>\n",
       "      <td>-0.075411</td>\n",
       "      <td>-0.046009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292950</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310330</td>\n",
       "      <td>0.354413</td>\n",
       "      <td>0.335381</td>\n",
       "      <td>0.433126</td>\n",
       "      <td>0.758386</td>\n",
       "      <td>0.438863</td>\n",
       "      <td>0.488459</td>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>0.048048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235306</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731341</td>\n",
       "      <td>0.734535</td>\n",
       "      <td>0.548252</td>\n",
       "      <td>0.304629</td>\n",
       "      <td>0.338420</td>\n",
       "      <td>0.321991</td>\n",
       "      <td>0.339444</td>\n",
       "      <td>-0.057172</td>\n",
       "      <td>-0.075411</td>\n",
       "      <td>-0.046009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187628</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278301</td>\n",
       "      <td>0.735457</td>\n",
       "      <td>0.787859</td>\n",
       "      <td>0.313780</td>\n",
       "      <td>0.700493</td>\n",
       "      <td>0.799430</td>\n",
       "      <td>0.464530</td>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>0.048048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200243</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247176</td>\n",
       "      <td>0.052474</td>\n",
       "      <td>0.172384</td>\n",
       "      <td>0.552959</td>\n",
       "      <td>0.405473</td>\n",
       "      <td>0.266106</td>\n",
       "      <td>0.531018</td>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>0.048048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155878</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305348</td>\n",
       "      <td>0.680329</td>\n",
       "      <td>0.534171</td>\n",
       "      <td>0.381683</td>\n",
       "      <td>0.435032</td>\n",
       "      <td>0.490791</td>\n",
       "      <td>0.263918</td>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>0.048048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10  ...  \\\n",
       "277491     6     4     2     7    34     1    31    60     1    148  ...   \n",
       "59826     11     1     1    13    34     3    20     4    13    258  ...   \n",
       "100532     6    10     1     5    34     3     1    36     1     76  ...   \n",
       "127444     8    13     1     6     3     1     9    60     1    148  ...   \n",
       "268466    13     1     2     5    34     1     9    52     5    160  ...   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...   \n",
       "292950     8    13     1     6     3     5    47    51     1    175  ...   \n",
       "235306     6     3     1     5    34     3    20    11     1     55  ...   \n",
       "187628    15     3     1     6    34     1    37    34     1    148  ...   \n",
       "200243     6     1     2     5     3     1    10    47     5    175  ...   \n",
       "155878     6     4     1     6    34     3    23    37     1    119  ...   \n",
       "\n",
       "           cont4     cont5     cont6     cont7     cont8     cont9    cont10  \\\n",
       "277491  0.292775  0.210421  0.335680  0.508110  0.375804  0.485737  0.388535   \n",
       "59826   0.717059  0.555945  0.253756  0.810781  0.558822  0.821682  0.950494   \n",
       "100532  0.300573  0.807069  0.559432  0.310892  0.414348  0.328559  0.198210   \n",
       "127444  0.260020  0.762579  0.929469  0.368868  0.400274  0.582639  0.436348   \n",
       "268466  0.292645  0.487171  0.581556  0.332349  0.366024  0.374952  0.382322   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "292950  0.310330  0.354413  0.335381  0.433126  0.758386  0.438863  0.488459   \n",
       "235306  0.731341  0.734535  0.548252  0.304629  0.338420  0.321991  0.339444   \n",
       "187628  0.278301  0.735457  0.787859  0.313780  0.700493  0.799430  0.464530   \n",
       "200243  0.247176  0.052474  0.172384  0.552959  0.405473  0.266106  0.531018   \n",
       "155878  0.305348  0.680329  0.534171  0.381683  0.435032  0.490791  0.263918   \n",
       "\n",
       "          cat0_0    cat0_1    cat0_2  \n",
       "277491  0.055748  0.038975  0.048048  \n",
       "59826   0.055748  0.038975  0.048048  \n",
       "100532 -0.057172 -0.075411 -0.046009  \n",
       "127444  0.055748  0.038975  0.048048  \n",
       "268466 -0.057172 -0.075411 -0.046009  \n",
       "...          ...       ...       ...  \n",
       "292950  0.055748  0.038975  0.048048  \n",
       "235306 -0.057172 -0.075411 -0.046009  \n",
       "187628  0.055748  0.038975  0.048048  \n",
       "200243  0.055748  0.038975  0.048048  \n",
       "155878  0.055748  0.038975  0.048048  \n",
       "\n",
       "[60000 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.tabular.all import *\n",
    "from fastcore.utils import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df_nn = pd.read_csv('dataset/train.csv', low_memory=False)\n",
    "df_nn_final = df_nn.drop('id', axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Categorical embedding\n",
    "\"\"\"\n",
    "\n",
    "cont,cat = cont_cat_split(df_nn_final, max_card=9000, dep_var='target')\n",
    "procs_nn = [Categorify, Normalize]\n",
    "splits = RandomSplitter(seed=23)(df_nn_final)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "to_nn = TabularPandas(df_nn, procs_nn, cat, cont,\n",
    "                      splits=splits, y_names='target')\n",
    "dls = to_nn.dataloaders(1024, device = device)\n",
    "\n",
    "learn = tabular_learner(dls, layers=[500,250], n_out=1)\n",
    "learn.fit_one_cycle(8, 5e-4)\n",
    "\n",
    "preds,targs = learn.get_preds()\n",
    "roc_auc_score(targs, preds)\n",
    "\n",
    "learn.save('learn8')\n",
    "\n",
    "# Machine Learning Models\n",
    "df = pd.read_csv('dataset/train.csv', low_memory=False)\n",
    "df = df.drop('id', axis=1)\n",
    "# using the neural net's `cat`, `cont`, and `splits`\n",
    "procs = [Categorify]\n",
    "to = TabularPandas(df, procs, cat, cont, 'target', splits = splits)\n",
    "\n",
    "def rf(xs, y, n_estimators=40, max_samples=130_000,\n",
    "       max_features=0.5, min_samples_leaf=5, **kwargs):\n",
    "    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n",
    "        max_samples=max_samples, max_features=max_features,\n",
    "        min_samples_leaf=min_samples_leaf).fit(xs, y)\n",
    "\n",
    "def auc(m, xs, y):\n",
    "    preds = m.predict(xs)\n",
    "    return round(roc_auc_score(y, preds), 3)\n",
    "\n",
    "# Replacing Nominal variables with Embeddings\n",
    "learn = learn.load('learn8')\n",
    "\n",
    "def embed_features(learner, xs):\n",
    "    \"\"\"\n",
    "    learner: fastai Learner used to train the neural net\n",
    "    xs: DataFrame containing input variables with nominal values defined by their rank.\n",
    "    ::returns:: a copy of `xs` with embeddings replacing each categorical variable\n",
    "    \"\"\"\n",
    "    xs = xs.copy()\n",
    "    for i,col in enumerate(learn.dls.cat_names):\n",
    "        emb = learn.model.embeds[i]\n",
    "        emb_data = emb(tensor(xs[col], dtype=torch.int64).to(device))\n",
    "        emb_names = [f'{col}_{j}' for j in range(emb_data.shape[1])]\n",
    "        feat_df = pd.DataFrame(data=emb_data, index=xs.index, columns=emb_names)\n",
    "        xs = xs.drop(col, axis=1)\n",
    "        xs = xs.join(feat_df)\n",
    "        return xs\n",
    "    \n",
    "emb_xs = embed_features(learn, to.train.xs)\n",
    "emb_valid_xs = embed_features(learn, to.valid.xs)\n",
    "emb_valid_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b39b9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SwapNoiseMasker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fx/shjw_pvd7zv34xd99rfzhz2h0000gn/T/ipykernel_7325/2414198730.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mswap_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnoise_maker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSwapNoiseMasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswap_probas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"the probability vector is of size {sum(repeats)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SwapNoiseMasker' is not defined"
     ]
    }
   ],
   "source": [
    "repeats = [  2,  2,  2,  2,  2,  2,  3,  4,  4, 4,  5]\n",
    "probas =  [.95, .4, .7, .9, .9, .9, .9, .9, .9, .9, .25]\n",
    "swap_probas = sum([[p] * r for p, r in zip(probas, repeats)], [])\n",
    "\n",
    "noise_maker = SwapNoiseMasker(swap_probas)\n",
    "print(f\"the probability vector is of size {sum(repeats)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edcfad4",
   "metadata": {},
   "source": [
    "## 2. Test with only Kmeans \n",
    "* To do: To test a better algorithme like DCN, deep clusterNet\n",
    "* Peut être essayer de rajouter un kfold ? Car score à 0.9 pour AUC c'est top délire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e4115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (380x32 and 30x15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fx/shjw_pvd7zv34xd99rfzhz2h0000gn/T/ipykernel_7325/1287117175.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m#x, mask = noise_maker.apply(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Predict soft-targets and embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_clust\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# negative log likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fx/shjw_pvd7zv34xd99rfzhz2h0000gn/T/ipykernel_7325/1287117175.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, n_clusters)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (380x32 and 30x15)"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utils import *\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        \"\"\"\n",
    "        To add dropout or other idk\n",
    "        input_size: df.shape[1]\n",
    "        output_size: nb_clust\n",
    "        \"\"\"\n",
    "        #self.fc1 = nn.Linear(in_features =input_size, out_features = 20)\n",
    "        self.fc1 = nn.Linear(in_features =input_size, out_features = output_size)\n",
    "\n",
    "        #self.fc2 = nn.Linear(in_features = 20, out_features=output_size)\n",
    "        self.fc3 = nn.Linear(in_features=output_size, out_features=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(num_features=output_size)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=output_size)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, n_clusters):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        #x = self.fc2(x)\n",
    "        #x = self.bn2(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        if n_clusters == 2:\n",
    "            # binary classification\n",
    "            # returns a probability scalar\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "            \n",
    "        else:\n",
    "            # clustering\n",
    "            # return a vector of size number of clusters\n",
    "            #x = self.fc2(x)\n",
    "            return x\n",
    "    \n",
    "\n",
    "train_loader, valid_loader = pandas_to_tensor(df, emb_xs, emb_valid_xs)\n",
    "\n",
    "nb_clust = 15\n",
    "\n",
    "# -1 cause we remove the target\n",
    "net = Net(df.shape[1] -1, nb_clust)\n",
    "kmeans = KMeans(n_clusters=nb_clust, random_state=0)\n",
    "#kmeans = KModes(n_clusters=nb_clust, init='Huang', n_init=5)\n",
    "\n",
    "max_epochs = 10\n",
    "#loss_fct = nn.CrossEntropyLoss()\n",
    "loss_fct_binary = nn.BCEWithLogitsLoss()\n",
    "loss_fct_clustering = nn.CrossEntropyLoss()\n",
    "\n",
    "l_loss = list()\n",
    "l_loss_intermediate = list()\n",
    "l_loss_test = list()\n",
    "l_roc_train = list()\n",
    "l_roc_intermediary = list()\n",
    "l_roc_test = list()\n",
    "\n",
    "optim = opt.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    \"\"\"\n",
    "    Unsupervised: Pre-learning we learn with the pseudo labels from clustering\n",
    "    \"\"\"\n",
    "    t0 = datetime.now()\n",
    "    net.train()\n",
    "    for batch, (x, _) in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        #x, mask = noise_maker.apply(x)\n",
    "        # Predict soft-targets and embeddings\n",
    "        output = net(x, nb_clust)\n",
    "        \n",
    "        # negative log likelihood\n",
    "        m = nn.Softmax(dim=1)\n",
    "        pseudo_labels = kmeans.fit_predict(output.detach())\n",
    "        # note that in the loss I used to do m(output) that is re apply a softmax -> not necessary I think\n",
    "        loss = loss_fct_clustering(output, torch.tensor(pseudo_labels.astype(np.int8), dtype=torch.long))\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        l_loss.append(loss.item())\n",
    "        #l_roc_train.append(roc_auc_score(y.detach().numpy(), proba.detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46248ee",
   "metadata": {},
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad and 'fc1' in name:\n",
    "        param.requires_grad = False\n",
    "    elif param.requires_grad and 'fc2' in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "optim = opt.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.01)\n",
    "\n",
    "max_epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    \"\"\"\n",
    "    Supervised: Second batch we learn to predict binary classification problem\n",
    "    \"\"\"\n",
    "    t0 = datetime.now()\n",
    "    net.train()\n",
    "    for batch, (x, y) in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = net(x, 2)\n",
    "        \n",
    "        loss = loss_fct_binary(output, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        l_loss_intermediate.append(loss.item())\n",
    "        #l_roc_intermediary.append(roc_auc_score(y.detach().numpy(), proba.detach().numpy()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdeb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \"\"\"\n",
    "    Testing\n",
    "    \"\"\"\n",
    "    for batch, (x, y) in enumerate(valid_loader):\n",
    "        output = net(x, 2)\n",
    "\n",
    "        loss = loss_fct_binary(output, y)\n",
    "        l_loss_test.append(loss)\n",
    "        \n",
    "        l_roc_test.append(roc_auc_score(y.detach().numpy(), torch.sigmoid(output).detach().numpy()))\n",
    "        \n",
    "print_scores(l_loss, l_roc_train,l_loss_intermediate, l_roc_intermediary, l_roc_test, l_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d4715",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3a4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afc5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df84a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e8492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba95d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd210a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
